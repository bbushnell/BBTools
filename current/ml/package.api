#version 1
#package ml
#generated 2025-09-06T20:37:45

<class Bell>
public class Bell

#Fields
static final String name="BELL"

static final int type=Function.toType(name,true)

static final Bell instance=new Bell()


#Methods
private Bell()

@Override public double activate(double x)

@Override public double derivativeX(double x)

@Override public double derivativeFX(double fx)

@Override public double derivativeXFX(double x, double fx)

@Override public int type()

@Override public String name()

</class Bell>
<class Cell>
public class Cell

#Fields
public float eTotalOverOut

public float outOverNet

public float eOverNet

public double sum=0

public float bias

private double biasDelta

public double error

private final int id

final int lpos

final int layer

final int maxLayer

int nextWeight=0

Function function

final int prevLayerStart

final int nextLayerStart

public int[] inputs

public int[] outputs

public float[] weights

float[] deltas

private final float[] values

public final float[] eOverNetArray

public static int MAX_TYPE=Function.TANH

public static int defaultActivationType=Function.SIG

public static int finalLayerType=Function.RSLOG

public static float randomTypeRate=0.0f

static float biasAlphaMult=1f

static float biasAnnealMult=0.5f

static boolean annealBias=true

private static float lowWeightAnnealCutoff=0.2f

private static float lowWeightAnnealMult=1f / lowWeightAnnealCutoff

static float cutoffForTraining=0.5f

static boolean setCutoffForTraining=false

static boolean useMidpoint=false

static float positiveErrorMult=1.0f

static float falsePositiveErrorMult=10.5f

static float excessPositiveErrorMult=0.2f

static float negativeErrorMult=1.0f

static float falseNegativeErrorMult=10.5f

static float excessNegativeErrorMult=0.2f

static float fnErrorIncr=0.01f

static float fpErrorIncr=0.00f

static float spread=0.050f

static float edgeAmplitudeIncreaseMult=0.98f

static float edgeAmplitudeIncreaseThresh=0.1f


#Methods
public Cell(int id_, int activationType, int lpos_, int layer_, int maxLayer_, int prevLayerStart_, int nextLayerStart_, int wid, float[] values_, float[] eOverNetArray_)

public void summateDense(float[] valuesIn)

public void summateSparse(float[] valuesIn, int edgeBlockSize)

public float calcError(float ideal)

public boolean check()

void applyUpdates(float invSamples, float alpha)

public void addError(float e)

public void clearError()

public void clearTemp()

public void setBias(float b2, boolean ignoreAssertion)

private void adjustBias(float invSamples, float alpha)

public void addError(Cell c2)

@Override public void setValue(float v)

public final double activation(double x)

public final double derivativeXFX(double x, double fx)

void updateEdgesFinalLayerDense(float target, float[] valuesIn, float weightMult)

public void updateEdgesHiddenLayerDense(float[] valuesIn, float[] eOverNetNext, float[] weightsOut)

public void updateEdgesHiddenLayerSparse(float[] valuesIn, float[] eOverNetNext, float[] weightsOut, int edgeBlockSize)

public void accumulate(Cell c2)

public void anneal(float strength, Random randy)

public void setFrom(Cell c, boolean copyDelta)

@Override public String toString()

@Override public boolean terminal()

public int id()

public float bias()

public static float toWeightedError(double rawError, float v, float target, float weightMult)

public static double toErrorIncr(double rawError, float v, float target)

public static float toErrorMult(float v, float target, float multFraction)

public static float calcETotalOverOut(float v, float target, float weightMult)

public static void setLowWeightAnnealCutoff(float c)

public final String typeString()

public void updateEdgesHiddenLayerDense(float alpha, float[] valuesIn, double[] eOverNetNext, float[] weightsOut)

public Cell(int size, int type, int i, int layerNum, int prevWidth, int width, int nextWidth, float[] lvals, double[] eons)

</class Cell>
<class CellNet>
*Multi-layer feedforward neural network.
*Supports dense and sparse connectivity, backpropagation training,
*and configurable activation functions.
*@author Brian Bushnell
*@date October 25, 2013
*@documentation Eru
public class CellNet

#Fields
*Current classification error rate (0.0-1.0)
float errorRate=999

*Weighted classification error rate accounting for class imbalance
float weightedErrorRate=999

*False positive rate - incorrectly classified as positive
float fpRate=999

*False negative rate - incorrectly classified as negative
float fnRate=999

*True positive rate - correctly classified as positive
float tpRate=-999

*True negative rate - correctly classified as negative
float tnRate=-999

*Learning rate for weight updates
float alpha=-1

*Simulated annealing strength for noise injection
float annealStrength=-1

*Classification threshold for binary decisions
public float cutoff=-1

*Current training epoch number
int epoch=-1

*Display counter for printing progress
int count=1

*Total epochs completed during training
long epochsTrained=0

*Total samples processed during training
long samplesTrained=0

*Last recorded training statistics string
String lastStats=null

*Random seed for reproducible weight initialization
final long seed

*Number of layers in network (including input and output)
final int layers

*Neuron count per layer [input, hidden1, hidden2, ..., output]
final int[] dims

*Connection density for hidden layers (0.0-1.0)
final float density

*Special connection density for first hidden layer
final float density1

*Block size for structured sparsity patterns
final int edgeBlockSize

*2D network structure [layer][neuron]
final Cell[][] net

*Direct reference to output layer for efficiency
final Cell[] finalLayer

*Global list of all neurons (index 0 reserved)
final ArrayList<Cell> list

*Activation values per layer [layer][neuron]
final float[][] values

*Error gradients per layer [layer][neuron]
final float[][] eOverNet

*Input weight matrices [layer][neuron][input_weight]
float[][][] weightsIn

*Output weight matrices for backpropagation [layer][neuron][output_weight]
float[][][] weightsOut

*Input connectivity indices for sparse networks [layer][neuron][input_id]
int[][][] edgesIn

*Output connectivity indices for sparse networks [layer][neuron][output_id]
int[][][] edgesOut

*Temporary counters for sparse matrix transpose operations
final int[] transposeCounter

*Starting global ID for each layer in the cell list
final int[] layerStart

*Command line arguments used to create this network.
*Enables network reproduction with identical parameters.
*Contains original training configuration and hyperparameters.
public ArrayList<String> commands

*Number of lines written during last serialization operation
long lastLinesWritten=0

*Enable vectorized fused multiply-add operations for ~20% speedup
public static final boolean SPECIAL_FMA=true

*Whether to apply bias normalization during training
public static boolean NORMALIZE_BIAS=false

*Whether to apply weight normalization during training
public static boolean NORMALIZE_WEIGHTS=false

*Strength of normalization applied (0.0-1.0)
public static float normalization_factor=0.125f

*Rate of normalization strength decay per epoch
public static float normalization_shrink_rate=0.999f

*Use compact serialization format
public static boolean CONCISE=true

*Network type: true=dense connectivity, false=sparse
public static boolean DENSE=true

*Output format: use hexadecimal encoding
public static boolean OUT_HEX=false

*Output format: force dense representation
public static boolean OUT_DENSE=false

*Output format: force sparse representation
public static boolean OUT_SPARSE=false

*Enable verbose debug output
public static boolean verbose=false

*Network file format version number
public static final int version=1

*Probability of uniform distribution in weight initialization
public static float PROB_FLAT=0.3f

*Probability of exponential distribution in weight initialization
public static float PROB_EXP=0.4f

*Lambda parameter for exponential distribution
public static float EXP_LAMDA=5f

*Maximum absolute weight value to prevent training instability
public static float RAND_WEIGHT_CAP=2.0f

*Current comparison metric for network sorting (0=WER, 1=ERR, 2=FNR, 3=FPR)
static int compareCode=0

*Comparison codes for different error metrics
static final int compareWER=0

*Comparison codes for different error metrics
static final int compareERR=1

*Comparison codes for different error metrics
static final int compareFNR=2

*Comparison codes for different error metrics
static final int compareFPR=3


#Methods
*Creates an empty dummy neural network with null fields.
*Used as placeholder during construction or for testing purposes.
*All parameters are set to safe default values indicating an uninitialized state.
public CellNet()

*Creates multi-layer feedforward neural network with specified topology.
*Initializes network structure, allocates memory for activations and gradients,
*and sets up layer connectivity patterns based on density parameters.
*Network uses dims[0] input neurons, dims[dims.length-1] output neurons,
*and dims.length-2 hidden layers. Connection density controls sparsity:
*density=1.0 creates fully connected layers, lower values create sparse connections.
*Edge block size enables structured sparsity for better memory locality.
*@param dims_ Neurons per layer array (must have at least 2 layers)
*@param seed_ Random seed for weight initialization (negative uses system time)
*@param density_ Connection density for hidden layers (0.0-1.0, typically 0.1-1.0)
*@param density1_ First hidden layer density override (0 uses density_ value)
*@param edgeBlockSize_ Connectivity block size for structured sparsity (power of 2)
*@param commands_ Command line arguments used to create network (for reproducibility)
public CellNet(int[] dims_, long seed_, float density_, float density1_, int edgeBlockSize_, ArrayList<String> commands_)

void makeWeightMatrices()

private float[][][] makeWeightsInMatrix()

*Creates input edge connectivity matrix for sparse networks.
*Structure: edgesIn[layer][neuron][input_index]
*Maps which neurons in previous layer connect to each neuron.
*@return 3D array with direct references to cell input arrays
private int[][][] makeEdgesInMatrix()

private float[][][] makeWeightsOutMatrix()

*Creates output edge connectivity matrix for sparse networks.
*Structure: edgesOut[layer][neuron][output_index]
*Maps which neurons in next layer each neuron connects to.
*@return 3D array with direct references to cell output arrays
private int[][][] makeEdgesOutMatrix()

public void randomize()

*Randomizes activation functions using cumulative distribution weights.
*Applies weighted random selection to hidden layer neurons only.
*Input and output layers retain their default activation functions.
*@param net Network layer structure
*@param list Global cell list (unused but kept for signature compatibility)
*@param randy Random number generator (seeded for reproducibility)
*@param cumRate Cumulative probability distribution for function types
static void randomizeActivationA(Cell[][] net, ArrayList<Cell> list, Random randy, float[] cumRate)

*Randomizes activation functions using uniform probability distribution.
*Each hidden layer neuron has 'rate' probability of changing its function.
*Ensures the new function differs from the current one to guarantee change.
*@param net Network layer structure
*@param list Global cell list (unused but kept for signature compatibility)
*@param randy Random number generator (seeded for reproducibility)
*@param rate Probability (0.0-1.0) that each neuron changes function
static void randomizeActivationB(Cell[][] net, ArrayList<Cell> list, Random randy, float rate)

*Allocates 2D matrix for layer-wise neural network data storage.
*Creates one array per layer with size matching neuron count.
*Used for both activation values and error gradients.
*@param dims Array containing neuron count per layer
*@return 2D matrix [layer][neuron] initialized to zero
private static float[][] makeFloatMatrix(int[] dims)

private static Cell[][] makeNodes(int[] dims, ArrayList<Cell> list, float[][] values, float[][] eOverNext)

*Calculates effective connection density for a specific layer.
*First hidden layer can use special density1 parameter for different sparsity.
*Output layer is always fully connected (density=1.0).
*@param density Default connection density for hidden layers
*@param density1 Special density for first hidden layer (0 uses default)
*@param layer Layer number being processed (1-based for hidden layers)
*@param layers Total number of layers in network
*@return Effective density (0.0-1.0) for this layer
private static final float layerDensity(float density, float density1, int layer, int layers)

*Creates dense network connectivity with probabilistic edge pruning.
*Allocates full weight matrices but randomly zeros edges based on density.
*Output layer remains fully connected regardless of density parameters.
*Uses structured sparsity via edgeBlockSize for memory locality.
*@param net Network layer structure to initialize
*@param randy Random number generator for edge selection
*@param density Base connection probability for hidden layers
*@param density1 Special density for first hidden layer
*@param edgeBlockSize Block size for structured connectivity patterns
*@return Total number of non-zero edges created
private static long makeEdgesDense(Cell[][] net, Random randy, float density, float density1, int edgeBlockSize)

*Creates sparse network connectivity with explicit edge lists.
*Stores only non-zero connections to minimize memory usage.
*Output layer remains fully connected, hidden layers use density pruning.
*Must call makeOutputSets() afterward to build reverse connectivity.
*@param net Network layer structure to initialize
*@param randy Random number generator for edge selection
*@param density Base connection probability for hidden layers
*@param density1 Special density for first hidden layer
*@param edgeBlockSize Block size for structured connectivity patterns
*@return Total number of edges created
private static long makeEdgesSparse(Cell[][] net, Random randy, float density, float density1, int edgeBlockSize)

*Selects network edges using structured sparsity patterns.
*First determines target edge count based on density, then uses
*block-aligned selection for better memory locality. Ensures minimum
*connectivity to prevent disconnected neurons.
*@param width Number of potential connections (previous layer size)
*@param edgeBlockSize Block alignment for structured sparsity
*@param density Connection probability (0.0-1.0)
*@param randy Random number generator for edge selection
*@return BitSet marking selected edge positions
private static BitSet pickEdges(int width, int edgeBlockSize, float density, Random randy)

static int[] toArray(BitSet bs)

static void makeOutputSets(Cell[][] net)

private static float randomBias(Random randy, float probFlat)

private static float randomWeight(Random randy)

*Applies simulated annealing to all network weights.
*Adds controlled random noise to weights to escape local minima
*and improve generalization. Strength controls noise magnitude.
*@param strength Annealing intensity (higher = more noise)
*@param randy Random number generator for noise generation
void anneal(float strength, Random randy)

*Processes single training sample through complete forward/backward pass.
*Applies input, computes forward propagation, calculates error, and
*optionally performs backpropagation to update weights. Handles both
*dense and sparse network architectures automatically.
*@param s Training sample with input, target, and metadata
*@param backProp Whether to perform backpropagation weight updates
*@param weightMult Learning rate multiplier for this sample
public void processSample(Sample s, boolean backProp, float weightMult)

*Apply input values to the network's input layer.
*Copies values into the first layer's value array for processing.
*@param valuesIn Input values as FloatList (size must match input layer)
*@return This network for chaining
public CellNet applyInput(FloatList valuesIn)

*Apply input values to the network's input layer.
*@param valuesIn Input values as float array (length must match input layer)
*@return This network for chaining
public CellNet applyInput(float[] valuesIn)

*Perform forward propagation through the network.
*Automatically selects dense or sparse implementation based on network type.
*@return Output value from the final layer
public float feedForward()

*Forward propagation for sparse networks.
*Processes only active connections to improve performance.
*@return Output value from the final layer
public float feedForwardSparse()

public float feedForwardDense()

*Performs backpropagation for sparse networks using gradient descent.
*Computes gradients from output layer backwards through hidden layers,
*updating weight deltas for later batch application. Uses sparse connectivity
*to skip non-existent edges for computational efficiency.
*@param truth Target output values for error computation
*@param weightMult Learning rate multiplier for gradient scaling
public void backPropSparse(float[] truth, float weightMult)

*Performs backpropagation for dense networks with optional optimizations.
*Uses vectorized operations when SPECIAL_FMA enabled for faster computation.
*Includes optional weight/bias normalization to prevent gradient explosion
*and improve training stability through standardization.
*@param truth Target output values for error computation
*@param weightMult Learning rate multiplier for gradient scaling
public void backPropDense(float[] truth, float weightMult)

*Normalizes bias values across hidden layers using z-score standardization.
*Computes mean and standard deviation for each layer, then applies
*weighted normalization to prevent extreme bias values that can
*destabilize training. Uses gradual adjustment to maintain stability.
public void normalizeBiasDense()

*Normalizes all network weights using layer-wise standardization.
*Applies z-score normalization to prevent gradient explosion and
*improve training convergence. Updates weight matrices and rebuilds
*transpose matrices for backpropagation consistency.
public void normalizeWeightsDense()

*Normalizes weight matrix using z-score standardization on non-zero values.
*Computes statistics over all non-zero weights to preserve sparsity,
*then applies weighted normalization to prevent extreme values.
*Ensures minimum weight magnitude to avoid underflow issues.
*@param weights 2D weight matrix to normalize
*@param list Reusable FloatList for statistics computation
public void normalizeDense(float[][] weights, FloatList list)

*Updates transpose weight matrices for backpropagation.
*Synchronizes weightsOut matrices with current weightsIn values
*to ensure gradient computation uses latest weights. Required
*after weight updates or normalization.
void transpose()

*Transposes dense weight matrices for backward pass computation.
*Copies weights from input-oriented (weightsIn) to output-oriented
*(weightsOut) format needed for gradient propagation. Uses direct
*matrix indexing for full connectivity.
void transposeDense()

*Transposes sparse weight matrices using connectivity mapping.
*Uses edge connectivity information to map weights from input-oriented
*to output-oriented format. Requires careful indexing due to sparse
*structure. Uses transposeCounter to track mapping progress.
void transposeSparse()

*Apply accumulated weight changes after a training batch.
*Updates all network weights using the specified learning rate and sample count.
*@param samples Number of samples processed in this batch
*@param alpha Learning rate for weight updates
public void applyChanges(int samples, float alpha)

*Get output value from a specific neuron in the final layer.
*@param outnum Index of output neuron (0-based)
*@return Activation value of the specified output neuron
public float getOutput(int outnum)

*Get all output values from the final layer.
*@return Array containing activation values of all output neurons
public float[] getOutput()

*Calculates total network error using legacy method.
*Computes sum of squared errors between predictions and targets.
*Deprecated in favor of Sample.calcError() for better error weighting.
*@param truth Target output values
*@return Total squared error across all outputs
*@deprecated Use Sample.calcError() for weighted error computation
@Deprecated public double calcError(float[] truth)

*Generates detailed string representation of network structure.
*Shows layer-by-layer breakdown with neuron details for debugging.
*Includes activation values, weights, and connectivity information.
*@return Multi-line string describing entire network state
public String toString()

*Generates network metadata header for serialization.
*Creates structured header with network parameters, training statistics,
*and performance metrics. Used for network file format output.
*@return ByteBuilder containing formatted network header
public ByteBuilder header()

*Serializes complete network to binary format with weights and structure.
*Outputs network in BBTools format with header, layer definitions,
*connectivity patterns, and weight values. Supports both dense and
*sparse representations with optional hexadecimal encoding.
*@return ByteBuilder containing complete serialized network
public ByteBuilder toBytes()

*Converts integer array to hexadecimal BitSet representation.
*Creates BitSet from integer indices then encodes as hex string.
*Used for compact sparse connectivity serialization.
*@param set Array of integer indices to encode
*@param bb ByteBuilder to append hex encoding to
*@return ByteBuilder with appended hex representation
static ByteBuilder toHex(int[] set, ByteBuilder bb)

*Converts BitSet to hexadecimal string representation.
*Encodes BitSet bytes as hex digits for compact storage.
*Note: Current implementation only uses digits 0-9, not full hex.
*@param bs BitSet to convert
*@param bb ByteBuilder to append hex string to
*@return ByteBuilder with appended hex representation
static ByteBuilder toHex(BitSet bs, ByteBuilder bb)

*Converts hexadecimal string back to integer array.
*Decodes hex-encoded BitSet back to original integer indices.
*Used for deserializing sparse connectivity patterns.
*@param line Byte array containing hex-encoded data
*@param start Starting position in byte array
*@return Integer array of decoded indices
static int[] fromHex(byte[] line, int start)

*Creates deep copy of network with identical architecture and state.
*Copies weights, biases, training statistics, and configuration parameters.
*Thread-safe operation for concurrent model evaluation and training.
*@param copyDelta Whether to copy accumulated gradients (for training)
*@return New CellNet instance with copied state
public CellNet copy(boolean copyDelta)

*Copies state from another network of identical architecture.
*Updates weights, biases, training statistics, and configuration
*parameters. Used for model checkpointing and population-based training.
*@param cn Source network to copy from
*@param copyWeight2 Whether to copy accumulated gradients (deltas)
*@return This network after copying
public CellNet setFrom(CellNet cn, boolean copyWeight2)

*Validates internal network consistency and state.
*Checks all neurons for valid weights, connectivity, and data integrity.
*Used for debugging and ensuring network correctness.
*@return true if network passes all consistency checks
public boolean check()

*Accumulates error gradients from another network.
*Adds gradient values from parallel training threads or batches.
*Used in distributed training and gradient accumulation.
*@param net2 Source network containing gradients to add
public void addError(CellNet net2)

*Thread-safe gradient accumulation from another network.
*Synchronizes access to prevent race conditions during parallel training.
*Used for multi-threaded batch processing and gradient aggregation.
*@param net2 Source network containing gradients to accumulate
public void accumulate(CellNet net2)

*Thread-safe clearing of temporary training data.
*Resets accumulated gradients and temporary variables.
*Called between training batches to prepare for next iteration.
public void clear()

*Counts total non-zero connections in the network.
*Iterates through all weight matrices to find active edges.
*Works for both dense and sparse networks by checking weight values.
*Used for network analysis and memory usage estimation.
*@return Number of non-zero weighted connections
public long countEdges()

*Compares networks based on performance metrics for ranking.
*Uses configurable comparison criteria (error rate, FPR, FNR, etc.)
*with fallback hierarchy for model selection and population sorting.
*Lower error rates are considered better (return 1).
*@param b Network to compare against
*@return 1 if this network is better, -1 if worse, 0 if equal
@Override public int compareTo(CellNet b)

*Gets the primary comparison metric value for this network.
*Returns the error metric currently used for network ranking.
*Used for quick access to sorting criterion without full comparison.
*@return Current primary error metric value
final float pivot()

*Get the number of layers in this network.
*@return Total number of layers including input and output
public int numLayers()

*Get the number of input neurons.
*@return Size of the input layer
public int numInputs()

*Get the number of output neurons.
*@return Size of the output layer
public int numOutputs()

*Sets classification threshold for binary prediction decisions.
*Values above cutoff are classified as positive, below as negative.
*Critical parameter for balancing precision/recall tradeoffs.
*@param f New cutoff threshold value (typically 0.0-1.0)
public void setCutoff(float f)

*Checks equality based on training epoch number.
*Networks are considered equal if trained for same number of epochs.
*Used for sorting and comparison during model selection.
*@param b Object to compare with
*@return true if both networks have same epoch count
@Override public boolean equals(Object b)

*Generates hash code based on training epoch.
*Consistent with equals() method for proper hash table behavior.
*@return Hash code derived from epoch number
@Override public int hashCode()

</class CellNet>
<class CellNetParser>
public class CellNetParser

#Fields
String fname

final ArrayList<byte[]> lines

private final CellNet net

long seed

float density=1f

float density1=0f

int edgeBlockSize=1

int edges=0

long epochs=0

long samples=0

int version

int layers=-1

boolean concise=false

boolean dense=true

int[] dims

int pos=0

float cutoff=0.5f

final int posFirstEdge

ArrayList<String> commands=new ArrayList<String>()

public static final byte delimiter=' '


#Methods
static CellNet parse(String fname, boolean nullOnFailure)

public static CellNet load(String fname)

public static CellNet load(String fname, boolean nullOnFailure)

private CellNetParser(String fname_)

private CellNetParser(ArrayList<byte[]> lines_)

public void parseHeader()

private void parseEdgesDense()

private void parseEdgesSparse()

boolean hasMore()

byte[] nextLine()

private static String parseString(byte[] line)

private static float parseFloat(byte[] line)

private static int parseInt(byte[] line)

private static long parseLong(byte[] line)

public static int[] parseIntArray(byte[] line, byte delimiter, boolean parseTitle)

</class CellNetParser>
<class CellNetReverseComparator>
public class CellNetReverseComparator

#Methods
@Override public int compare(CellNet a, CellNet b)

</class CellNetReverseComparator>
<class DataLoader>
*Loads and preprocesses machine learning datasets from files.
*Handles data parsing, shuffling, class balancing, and train/test splitting.
*Supports multiple file formats and automatic data type inference.
*@author Brian Bushnell
*@contributor Isla Winglet
*@version 1.0
public class DataLoader

#Fields
*Line parser for handling delimited data
LineParser1 lp=new LineParser1(delimiter)

*Array of file names to process
String fnames

*Loaded data matrix
Matrix matrix

*Current parsing position
int pos=0

*Count of successfully parsed lines
long validLines=0

*Count of invalid or unparseable lines
long invalidLines=0

*Valid lines from most recent load operation
static long lastValidLines=0

*Invalid lines from most recent load operation
static long lastInvalidLines=0

*Flag indicating whether weight columns are present
static boolean weighted=false

*Field delimiter character
public static final byte delimiter='\t'

*Flag to ignore malformed lines instead of failing
public static boolean IGNORE_BAD_LINES=false


#Methods
*Constructs a DataLoader for the specified file(s).
*Accepts either a single file path or comma-separated multiple files.
*@param fname_ File path or comma-separated list of file paths
private DataLoader(String fname_)

*Splits a matrix into training and validation sets.
*Distributes samples between sets while maintaining class balance.
*@param m Source matrix to split
*@param fraction Fraction of samples to assign to validation set
*@param maxLines1 Maximum lines allowed in validation set
*@param exclusive If true, creates independent sets; if false, training set contains all data
*@return Array of two matrices: [training, validation]
public static Matrix[] split(Matrix m, float fraction, int maxLines1, boolean exclusive)

*Loads dataset from file(s) and creates SampleSets for training.
*Handles file parsing, optional shuffling, train/test splitting, and class balancing.
*@param fname File path(s) to load data from
*@param maxLines0 Maximum lines to load initially
*@param shuffleRaw Whether to shuffle data after loading
*@param splitFraction Fraction for train/test split (0 for no split)
*@param maxLines1 Maximum lines in validation set
*@param exclusive Whether split sets should be independent
*@param balance Class balancing factor (0 for no balancing, 1 for perfect balance)
*@return Array of SampleSets: [training] or [training, validation]
public static SampleSet[] load(String fname, int maxLines0, boolean shuffleRaw, float splitFraction, int maxLines1, boolean exclusive, float balance)

*Internal method to load and preprocess data from files.
*Parses headers, processes data lines, applies shuffling and balancing.
*@param maxLines Maximum number of lines to process
*@param shuffleRaw Whether to shuffle the raw data
*@param balance Class balancing multiplier
private void load(int maxLines, boolean shuffleRaw, float balance)

*Randomly shuffles the dataset using a reproducible seed.
*Maintains correspondence between inputs, outputs, and weights.
*@param inputList List of input vectors
*@param outputList List of output vectors
*@param weightList List of weight vectors
*@param maxLines Maximum number of samples to retain after shuffling
private static void shuffle(ArrayList<float[]> inputList, ArrayList<float[]> outputList, ArrayList<float[]> weightList, int maxLines)

*Balances class representation by cloning underrepresented samples.
*Intelligently handles edge cases including single-class datasets.
*@param inputList List of input vectors to balance
*@param outputList List of output vectors to balance
*@param weightList List of weight vectors to balance
*@param mult Target balance multiplier (1.0 = perfect balance)
private static void balance(ArrayList<float[]> inputList, ArrayList<float[]> outputList, ArrayList<float[]> weightList, float mult)

*Parses a single data line into input, output, and weight arrays.
*Handles tab-separated values with optional weight column.
*@param line Raw byte array containing the data line
*@param inputs Array to populate with input values
*@param outputs Array to populate with output values
*@param weights Array to populate with weight values
*@return true if parsing was successful, false otherwise
boolean parseDataLine(byte[] line, float[] inputs, float[] outputs, float[] weights)

*Parses an integer value from a delimited line.
*@param line Byte array containing the line to parse
*@return Parsed integer value
private static int parseInt(byte[] line)

*Parses an array of integers from a delimited line.
*Optionally skips a title field at the beginning.
*@param line Byte array containing the line to parse
*@param delimiter Character used to separate fields
*@param parseTitle Whether to skip the first field as a title
*@return Array of parsed integer values
public static int[] parseIntArray(byte[] line, byte delimiter, boolean parseTitle)

</class DataLoader>
<class ExtendedMSig>
public class ExtendedMSig

#Fields
static final String name="EMSIG"

static final ExtendedMSig instance=new ExtendedMSig()


#Methods
private ExtendedMSig()

</class ExtendedMSig>
<class ExtendedSigmoid>
public class ExtendedSigmoid

#Fields
static final String name="ESIG"

static final ExtendedSigmoid instance=new ExtendedSigmoid()


#Methods
private ExtendedSigmoid()

</class ExtendedSigmoid>
<class Function>
public abstract class Function

#Fields
public static final int SIG=0

public static final int TANH=1

public static final int RSLOG=2

public static final int MSIG=3

public static final int SWISH=4

public static final int ESIG=5

public static final int EMSIG=6

public static final int BELL=7

static final String[] TYPES=new String[]{"SIG","TANH","RSLOG","MSIG","SWISH","ESIG","EMSIG","BELL"}

static final String[] TYPES_LONG=new String[]{"SIGMOID","HYPERBOLICTANGENT","ROTATIONALLYSYMMETRICLOGARITHM","MIRROREDSIGMOID","SWISH","EXTENDEDSIGMOID","EXTENDEDMIRROREDSIGMOID","GAUSSIAN"}

private static final Function[] functions=makeFunctions()

public static final float[] TYPE_RATES=new float[TYPES.length]

public static float[] TYPE_RATES_CUM=null


#Methods
public double activate(double x)

public double derivativeX(double x)

public double derivativeFX(double fx)

public double derivativeXFX(double x, double fx)

public int type()

public String name()

static final int toType(String b)

static final int toType(String b, boolean assertValid)

public static final void normalizeTypeRates()

public static final Function getFunction(int type)

private static final Function[] makeFunctions()

static final Function randomFunction(Random randy)

static final int randomType(Random randy, float[] cumRate)

</class Function>
<class Functions>
public class Functions

#Fields
private static final double MSIG_X_OFFSET=5

private static final double MSIG_X_MULT=2

private static final double MSIG_Y_MULT=1.0 / sigmoid(MSIG_X_OFFSET)


#Methods
public static double sigmoid(double x)

static final double sigmoidDerivativeX(double x)

static final double sigmoidDerivativeFX(double fx)

static final double sigmoidDerivativeXFX(double x, double fx)

public static double eSigmoid(double x)

static final double eSigmoidDerivativeX(double x)

static final double eSigmoidDerivativeFX(double fx)

static final double eSigmoidDerivativeXFX(double x, double fx)

public static float tanh(double x)

static final double tanhDerivativeX(double x)

static final double tanhDerivativeFX(double fx)

static final double tanhDerivativeXFX(double x, double fx)

public static double swish(double x)

public static double swishDerivativeX(double x)

static final double swishDerivativeFX(double fx)

public static double swishDerivativeXFX(double x, double fx)

public static double swishDerivativeFXSIGX(double fx, double sigx)

public static double rslog(double x)

static final double rslogDerivativeX(double x)

static final double rslogDerivativeFX(double fx)

static final double rslogDerivativeXFX(double x, double fx)

public static double mSig(double x)

static final double mSigDerivativeX(double x)

static final double mSigDerivativeFX(double fx)

static final double mSigDerivativeXFX(double x, double fx)

public static double emSig(double x)

static final double emSigDerivativeX(double x)

static final double emSigDerivativeFX(double fx)

static final double emSigDerivativeXFX(double x, double fx)

public static double bell(double x)

static final double bellDerivativeX(double x)

static final double bellDerivativeFX(double fx)

static final double bellDerivativeXFX(double x, double fx)

public static double mse(float[] target, float[] actual)

</class Functions>
<class JobData>
public class JobData

#Fields
final CellNet immutableNet

CellNet mutableNet

final ArrayBlockingQueue<JobResults> jobResultsQueue

final int epoch

final int maxSamples

final double alpha

final boolean backprop

final float weightMult

final boolean sort

final boolean doCopy

final int jid

final int jobsPerEpoch

final ArrayList<Sample> list

final Sample[] set

final ReentrantReadWriteLock setLock

static final JobData POISON=new JobData(null,null,-1,-1,-1,false,0.0f,false,false,null,null,null,-1,-1)


#Methods
JobData(CellNet net_, ArrayBlockingQueue<JobResults> jrq_, int epoch_, int maxSamples_, double alpha_, boolean backprop_, float weightMult_, boolean sort_, boolean doCopy_, ArrayList<Sample> list_, Sample[] set_, ReentrantReadWriteLock setLock_, int jid_, int jpe_)

public String toString()

</class JobData>
<class JobResults>
public class JobResults

#Fields
final CellNet net

final int epoch

final int numProcessed

final int tid

final int jid

final double errorSum

final double weightedErrorSum

final int tpSum

final int tnSum

final int fpSum

final int fnSum

static final JobResults POISON=new JobResults(null,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1)


#Methods
JobResults(CellNet net_, int epoch_, int numProcessed_, int tid_, int jid_, double errorSum_, double weightedErrorSum_, int tpSum_, int tnSum_, int fpSum_, int fnSum_)

public String toString()

@Override public int compareTo(JobResults o)

</class JobResults>
<class Matrix>
*Represents a data matrix for machine learning operations.
*Handles input/output data transformation, range detection, and format conversion.
*Supports automatic range adjustment and binary classification conversion.
*@author Brian Bushnell
*@contributor Isla Winglet
*@version 1.0
public class Matrix

#Fields
*Column headers for data interpretation
ArrayList<String> columns

*Dimensional structure of the data
int[] dims

*Number of input features per sample
int numInputs

*Number of output values per sample
int numOutputs

*Count of positive examples in the dataset
int numPositive=0

*Count of negative examples in the dataset
int numNegative=0

*Number of successfully parsed data lines
int validLines=0

*Number of unparseable or invalid data lines
int invalidLines=0

*Minimum value in the output data
private float outputMin

*Maximum value in the output data
private float outputMax

*Mean of all output values
private float outputMean

*Midpoint of the output range (used for classification threshold)
private float outputMidpoint

*Range of output values (max - min)
private float outputRange

*Complete data structure: [inputs, outputs, weights]
float[][][] data

*Input feature vectors for each sample
float[][] inputs

*Output target values for each sample
float[][] outputs

*Sample weights for training emphasis
float[][] weights

*Flag to enable binary conversion of outputs
static boolean convertTo01=false

*Target minimum value for range adjustment
static float targetOutputRangeMin=0

*Target maximum value for range adjustment
static float targetOutputRangeMax=0

*Flag indicating whether to set custom minimum range
static boolean setTargetOutputRangeMin=false

*Flag indicating whether to set custom maximum range
static boolean setTargetOutputRangeMax=false


#Methods
*Initializes the matrix by detecting data ranges and applying transformations.
*Performs range detection, optional binary conversion, and range adjustment.
void initializeRange()

*Analyzes output data to determine min, max, mean, and midpoint values.
*Calculates statistical properties of the output data for normalization
*and classification threshold determination.
void detectRange()

*Converts continuous output values to binary (0 or 1) classification.
*Values below the cutoff become 0, values at or above become 1.
*Updates all statistical measures to reflect the binary conversion.
*@param cutoff Threshold value for binary conversion
void convertToZeroOne(float cutoff)

*Adjusts output values to fit within specified target range.
*Linearly scales all output values to match the desired min/max bounds.
*Recalculates all statistical measures after adjustment.
void adjustRange()

*Generates a string representation of the matrix properties.
*Includes column headers, dimensions, and statistical measures.
*@return Formatted string describing the matrix
public String toString()

*Returns the number of input features.
*@return Number of input dimensions
int numInputs()

*Returns the number of output dimensions.
*@return Number of output values
int numOutputs()

*Returns the midpoint value of the output range.
*Used as the default threshold for binary classification.
*@return Output range midpoint
public float outputMidpoint()

</class Matrix>
<class MSig>
public class MSig

#Fields
static final String name="MSIG"

static final MSig instance=new MSig()


#Methods
private MSig()

</class MSig>
<class NetFilter>
*Filters sequences based on matching a neural network.
*@author Brian Bushnell
*@date November 1, 2023
public class NetFilter

#Fields
*Primary input file path
private String in1=null

*Secondary input file path
private String in2=null

private String qfin1=null

private String qfin2=null

*Primary output file path
private String out1=null

*Secondary output file path
private String out2=null

private String outu1=null

private String outu2=null

private String qfout1=null

private String qfout2=null

*Override input file extension
private String extin=null

*Override output file extension
private String extout=null

*Whether interleaved was explicitly set.
private boolean setInterleaved=false

private String netFile=null

private String histFile=null

private final FileFormat ffnet

private LongList phist=new LongList(101)

private LongList mhist=new LongList(101)

private boolean parseHeader=false

private final CellNet net0

*For raw sequence classification
private boolean rcomp=false

private int width=-1

*For kmer spectrum classification
private int k=0

private int dims

private boolean filter=true

private boolean highpass=true

private boolean annotate=false

private float cutoff=0.5f

private boolean autoCutoff=true

private int stepsize=1

private int overlap=Integer.MIN_VALUE

private int SCORE_MODE=SINGLE

private int PAIR_MODE=AVERAGE

private static final int SINGLE=0

private static final int AVERAGE=1

private static final int MAX=2

private static final int MIN=3

private static final String[] MODES={"single","average","max","min"}

*Number of reads processed
protected long readsProcessed=0

*Number of bases processed
protected long basesProcessed=0

*Number of reads retained
protected long readsOut=0

*Number of bases retained
protected long basesOut=0

double scoreSum=0

double scoreSumPositive=0

double scoreSumNegative=0

double scoreSumPass=0

double scoreSumFail=0

long scoreCount=0

long scoreCountPositive=0

long scoreCountNegative=0

long scoreCountPass=0

long scoreCountFail=0

long fpCount=0

long fnCount=0

long tpCount=0

long tnCount=0

*Quit after processing this many input reads; -1 means no limit
private long maxReads=-1

*Primary input file
private final FileFormat ffin1

*Secondary input file
private final FileFormat ffin2

*Primary output file
private final FileFormat ffout1

*Secondary output file
private final FileFormat ffout2

*Unmatched output file
private final FileFormat ffoutu1

*Secondary unmatched output file
private final FileFormat ffoutu2

private final ReadWriteLock rwlock=new ReentrantReadWriteLock()

*Print status messages to this output stream
private PrintStream outstream=System.err

*Print verbose messages
public static boolean verbose=false

*True if an error was encountered
public boolean errorState=false

*Overwrite existing output files
private boolean overwrite=true

*Append to existing output files
private boolean append=false

*Reads are output in input order
private boolean ordered=true


#Methods
*Code entrance from the command line.
*@param args Command line arguments
public static void main(String[] args)

*Constructor.
*@param args Command line arguments
public NetFilter(String[] args)

*Parse arguments from the command line
private Parser parse(String[] args)

*Replace # with 1 and 2 in headers
private void doPoundReplacement()

*Add or remove .gz or .bz2 as needed
private void fixExtensions()

*Ensure files can be read and written
private void checkFileExistence()

*Make sure interleaving agrees with number of input and output files
private void adjustInterleaving()

*Adjust file-related static fields as needed for this program
private static void checkStatics()

*Ensure parameter ranges are within bounds and required parameters are set
private boolean validateParams()

*Create read streams and process all data
void process(Timer t)

private ConcurrentReadInputStream makeCris()

private ConcurrentReadOutputStream makeCros(boolean pairedInput, FileFormat ff1, FileFormat ff2, String qf1, String qf2)

*Spawn process threads
private void spawnThreads(ConcurrentReadInputStream cris, ConcurrentReadOutputStream ros, ConcurrentReadOutputStream rosu)

@Override public final void accumulate(ProcessThread pt)

@Override public final boolean success()

float score(byte[] bases, float[] vec, int k, CellNet net, boolean rcomp)

float score(byte[] bases, float[] vec, int k, CellNet net)

public static float scoreSingle(byte[] bases, float[] vec, int k, CellNet net)

public static float scoreFrames(byte[] bases, float[] vec, int k, CellNet net, int SCORE_MODE, int stepsize, int width)

public static float score(byte[] bases, float[] vec, int k, CellNet net, int from, int to)

private static int parseMode(String b)

@Override public final ReadWriteLock rwlock()

</class NetFilter>
<class NetFilter.ProcessThread>
class NetFilter.ProcessThread

#Fields
*Number of reads processed by this thread
protected long readsProcessedT=0

*Number of bases processed by this thread
protected long basesProcessedT=0

*Number of reads retained by this thread
protected long readsOutT=0

*Number of bases retained by this thread
protected long basesOutT=0

double scoreSumT=0

double scoreSumPositiveT=0

double scoreSumNegativeT=0

double scoreSumPassT=0

double scoreSumFailT=0

long scoreCountT=0

long scoreCountPositiveT=0

long scoreCountNegativeT=0

long scoreCountPassT=0

long scoreCountFailT=0

long fpCountT=0

long fnCountT=0

long tpCountT=0

long tnCountT=0

*True only if this thread has completed successfully
boolean success=false

private LongList phistT=new LongList(101)

private LongList mhistT=new LongList(101)

private CellNet net

private float[] vec

*Shared input stream
private final ConcurrentReadInputStream cris

*Shared output stream
private final ConcurrentReadOutputStream ros

*Shared unmatched output stream
private final ConcurrentReadOutputStream rosu

*Thread ID
final int tid


#Methods
ProcessThread(ConcurrentReadInputStream cris_, ConcurrentReadOutputStream ros_, ConcurrentReadOutputStream rosu_, int tid_)

@Override public void run()

*Iterate through the reads
void processInner()

void processList(ListNum<Read> ln)

*Process a read or a read pair.
*@param r1 Read 1
*@param r2 Read 2 (may be null)
*@return True if the reads should be kept, false if they should be discarded.
boolean processReadPair(Read r1, Read r2)

private float processRead(Read r, float[] vec)

</class NetFilter.ProcessThread>
<class ProcessBBMergeHeaders>
*@author Brian Bushnell
*@date June 1, 2016
public class ProcessBBMergeHeaders

#Fields
private String in1=null

private String out1=null

private final FileFormat ffin1

private final FileFormat ffout1

private long maxReads=-1

private java.io.PrintStream outstream=System.err

public static boolean verbose=false


#Methods
public static void main(String[] args)

public ProcessBBMergeHeaders(String[] args)

void process(Timer t)

private Header makeHeader(String line)

public String headerString()

</class ProcessBBMergeHeaders>
<class Profiler>
public class Profiler

#Fields
private long start

private int idx=0

final long[] times

final String prefix

public static boolean PROFILING=false


#Methods
public Profiler(String prefix_, int len_)

void log()

void log(int idx)

public String toString()

void printTimes()

void accumulate(Profiler p)

void reset()

void clear()

</class Profiler>
<class ReduceColumns>
public class ReduceColumns

#Methods
public static void main(String[] args)

</class ReduceColumns>
<class RSLog>
public class RSLog

#Fields
static final String name="RSLOG"

static final RSLog instance=new RSLog()


#Methods
private RSLog()

</class RSLog>
<class Sample>
public class Sample

#Fields
final boolean positive

float errorMagnitude=1

float weightedErrorMagnitude=1

private int epoch=-1

private int lastTID=-1

float pivot=0

final float[] in

final float[] goal

final float[] result

final float weight

final int id

public static float excessPivotMult=0.2f

public static final float EPOCH_MULT=1 / 256f


#Methods
public Sample(float[] in_, float[] out_, float weight_, int id_)

@Override public int compareTo(Sample o)

public boolean checkPivot()

void setPivot()

float calcPivot()

public String toString()

public ByteBuilder toBytes()

public ByteBuilder toBytes(ByteBuilder bb)

public void calcError(float weightMult)

public int epoch()

public int lastTID()

public void setEpoch(long x)

public void setLastTID(int x)

public static final float calcError(float goal, float pred)

</class Sample>
<class SampleErrorComparator>
public final class SampleErrorComparator

#Fields
public static SampleErrorComparator COMPARATOR=new SampleErrorComparator()


#Methods
private SampleErrorComparator()

@Override public int compare(Sample a, Sample b)

</class SampleErrorComparator>
<class SampleSet>
*Manages a set of machine learning samples for training and evaluation.
*Provides functionality for:
*- Sample generation
*- Subset creation
*- Performance metric calculations
*- ROC curve generation
*@author Brian Bushnell
*@contributor Nepgear
*@version 1.0
public class SampleSet

#Fields
final Matrix matrix

int numPositive=0

int numNegative=0

Sample[] samples

Sample[] samplesSortedByResult

private Subset[] subsets

private int currentSubset=0

private int numShuffles=0

static long shuffleSeed=0

static boolean shuffle=true

int nextSubsetEpoch=subsetInterval

static int subsetInterval=64


#Methods
*Constructs a SampleSet from a given matrix of input data.
*@param m Matrix containing input, output, and weight data
*@throws AssertionError if matrix weights are null
SampleSet(Matrix m)

*Generates samples using the maximum possible number of inputs.
void makeSamples()

*Generates samples from the input matrix, limited to a maximum number.
*Categorizes samples as positive or negative based on output midpoint.
*@param max Maximum number of samples to generate
void makeSamples(int max)

*Divides samples into multiple subsets for cross-validation.
*@param numSets Number of subsets to create
void makeSubsets(int numSets)

*Retrieves the current subset for a given training epoch.
*@param epoch Current training epoch
*@return Current subset of samples
Subset currentSubset(int epoch)

*Advances to the next subset, potentially shuffling samples.
private void advanceSubset()

*Randomly shuffles samples using a reproducible seed.
private void shuffle()

*Sorts samples by their predicted value.
public void sortByValue()

*Verifies that samples are correctly sorted by value.
*@return true if samples are sorted, false otherwise
public boolean checkSort()

*Calculates False Negative Rate for a given cutoff value.
*@param cutoff Threshold for classification
*@return False Negative Rate
public double calcFNRFromCutoff(double cutoff)

*Calculates cutoff value based on crossover point.
*@param fpMult False positive multiplier
*@return Calculated cutoff value
public float calcCutoffFromCrossover(double fpMult)

*Calculates False Positive Rate for a given cutoff.
*@param cutoff Threshold for classification
*@return False Positive Rate
public double calcFPRFromCutoff(double cutoff)

public double calcCutoffFromFPR(double fpr)

public double calcCutoffFromFNR(double fnr)

public double calcFNRFromFPR(double fpr)

public double calcFPRFromFNR(double fnr)

*Generates Receiver Operating Characteristic (ROC) curve.
*@param bins Number of bins for ROC curve
*@return ROC curve data points
public float[] calcROC(int bins)

*Creates a copy of the current sample set.
SampleSet copy()

*Creates a copy of the sample set with optional size and subset limitations.
*@param maxSamples Maximum number of samples to copy
*@param subsetSizeFraction Fraction of subset size to preserve
*@return Copied sample set
SampleSet copy(int maxSamples, float subsetSizeFraction)

*Resets the sample set to its initial state.
void reset()

*Returns the maximum size of a subset.
*@return Maximum subset size
public int maxSubsetSize()

final int numInputs()

final int numOutputs()

final float outputMidpoint()

</class SampleSet>
<class SampleValueComparator>
public final class SampleValueComparator

#Fields
public static SampleValueComparator COMPARATOR=new SampleValueComparator()


#Methods
private SampleValueComparator()

@Override public int compare(Sample a, Sample b)

</class SampleValueComparator>
<class ScannerThread>
*The goal of this thread is to generate lots of networks,
*evaluate them, and return the best candidates.
*@author BBushnell
public class ScannerThread

#Fields
private final Trainer parent

private final int[] dims0

private final int[] minDims

private final int[] maxDims

private final int seedsToEvaluate

private final int seedsToReturn

private final long netSeed0

private final PriorityQueue<CellNet> heap

final ArrayBlockingQueue<ArrayList<Seed>> returnQueue

private CellNet net0

private SampleSet data

private SampleSet validateSet

private Subset currentSubset

private Sample[] currentSamples

private final ReentrantReadWriteLock setLock

private final int jobsPerEpoch

private final boolean orderedJobs

private final ArrayBlockingQueue<JobResults> jobResultsQueue

private final ArrayBlockingQueue<JobData> workerQueue

private final ArrayBlockingQueue<JobData> launchQueue

final Profiler mprof=new Profiler("M",13)

private final boolean training

final int maxEpochs

final int maxSamples

final float targetError

final float targetFPR

final float targetFNR

final float crossoverFpMult

final boolean sortAll

final boolean sort

final boolean sortInThread

final boolean shuffleSubset

final boolean launchInThread

final double alpha

private final float fractionPerEpoch

float bestErrorRate=999

float bestFNR=999

double rawErrorSum=0

double weightedErrorSum=0

long tpSum=0

long tnSum=0

long fpSum=0

long fnSum=0

double rawErrorRate=999f

double weightedErrorRate=999f

double fpRate=0

double fnRate=0

double tpRate

double tnRate

double crossover

double lastCutoffForTarget=1.0f

private int samplesThisEpoch=-1

private boolean validateThisEpoch=false

private int currentEpoch=0

final Random randy

*Print status messages to this output stream
private PrintStream outstream=System.err

*Print verbose messages
public static boolean verbose=false

*True if an error was encountered
public boolean errorState=false


#Methods
public ScannerThread(Trainer parent_, int[] dims0_, int[] minDims_, int[] maxDims_, int seedsToEvaluate_, int seedsToReturn_, int epochs_, int maxSamples_, long netSeed0_, ArrayBlockingQueue<ArrayList<Seed>> returnQueue_)

@Override public void run()

private int runEpochs()

private void runTrainingInterval()

private void runTestingInterval(Sample[] set)

void lock()

void unlock()

private int launchJobs(CellNet net0, Sample[] set, int numSamples, boolean backprop, float weightMult, boolean sort)

private int launchJobsInner(CellNet net0, Sample[] set, int numSamples_, int epoch, double alpha, boolean backprop, float weightMult, boolean sort)

private int launchJobs_SetLock(CellNet net0, Sample[] set, int numSamples_, int epoch, double alpha, boolean backprop, float weightMult, boolean sort)

private void gatherResults(CellNet net0, ArrayBlockingQueue<JobResults> mq, boolean accumulate, int numJobs)

private void gatherResultsDisordered(CellNet net0, ArrayBlockingQueue<JobResults> mq, boolean accumulate, int numJobs)

private void gatherResultsOrdered(CellNet net0, ArrayBlockingQueue<JobResults> mq, boolean accumulate, int numJobs)

private void selectTrainingSubset()

private void clearStats()

private void gatherStats(JobResults job)

private void mergeStats(int samples)

void reviseCutoff()

private void setNetStats(CellNet net)

public final boolean success()

</class ScannerThread>
<class ScoreSequence>
*@author Brian Bushnell
*@date Oct 6, 2014
public class ScoreSequence

#Fields
private String in1=null

private String out1=null

private String netFile=null

private String histFile=null

private final FileFormat ffin1

private final FileFormat ffout1

private final FileFormat ffnet

private LongList phist=new LongList(101)

private LongList mhist=new LongList(101)

private long readsOut=0

private long maxReads=-1

private boolean errorState=false

private int k=0

private boolean rcomp=false

private boolean parseHeader=false

private int width=-1

private final CellNet net

private boolean filter=false

private boolean highpass=true

private boolean annotate=true

private float cutoff=0.5f

private java.io.PrintStream outstream=System.err

public static boolean verbose=false


#Methods
public static void main(String[] args)

public ScoreSequence(String[] args)

void process(Timer t)

private boolean processRead(Read r, ByteBuilder bb, ByteStreamWriter bsw, float[] vec)

public static float score(byte[] bases, float[] vec, int k, CellNet net, boolean rcomp)

public static float score(byte[] bases, float[] vec, int k, CellNet net)

public static float score(byte[] bases, float[] vec, int k, CellNet net, int from, int to)

</class ScoreSequence>
<class Seed>
public class Seed

#Fields
final long netSeed

final float pivot


#Methods
Seed(long netSeed_, float pivot_)

@Override public int compareTo(Seed s)

@Override public boolean equals(Object o)

public boolean equals(Seed s)

@Override public String toString()

</class Seed>
<class SequenceToVector>
*@author Brian Bushnell
*@date Oct 6, 2023
public class SequenceToVector

#Fields
private String in1=null

private String out1=null

private final FileFormat ffin1

private final FileFormat ffout1

private static final ThreadLocal<EntropyTracker[]> localETrackers=new ThreadLocal<EntropyTracker[]>(){
  @Override protected EntropyTracker[] initialValue(){
    EntropyTracker[] array=new EntropyTracker[maxWindow + 1];
    for (int i=minWindow; i < array.length; i++) {
      array[i]=new EntropyTracker(ke,i,false);
    }
    return array;
  }
}

private long maxReads=-1

private boolean errorState=false

private boolean rcomp=false

private boolean parseHeader=false

private int width=55

float result0=-1

final int k

final int fullSpace

final int kSpace

final int[] kmap

private static final int[] fullspaceArray

private static final int[] kspaceArray

private static final int[][] kmapArray

private static int maxDimensions=Integer.MAX_VALUE

private static final int kMax=8

private int mode=RAW

static final int RAW=0

static final int SPECTRUM=1

public static final int minWindow=16

public static final int maxWindow=40

public static final int ke=3

public static final String[] hotCodes=new String[]{"1\t0\t0\t0","0\t1\t0\t0","0\t0\t1\t0","0\t0\t0\t1","1\t0\t0\t0"}

private java.io.PrintStream outstream=System.err

public static boolean verbose=false


#Methods
public static void main(String[] args)

public SequenceToVector(String[] args)

void process(Timer t)

private static void toVector(Read r, ByteBuilder bb, ByteStreamWriter bsw, int width, int k, float result, float[] buffer, boolean rcomp)

private static ByteBuilder toVector(byte[] bases, ByteBuilder bb, int width, int k, float result, float[] buffer)

private static void appendRaw(byte[] bases, ByteBuilder bb, int width)

private static void appendSpectrum(ByteBuilder bb, float[] vec)

public static float[] fillVector(byte[] bases, float[] vec, int k)

public static float[] fillVector(byte[] bases, float[] vec, int k, int from, int to)

public static void fillRaw(byte[] bases, float[] vec, int offset, int from, int to)

public static int fillSpectrum(byte[] bases, float[] vec, int offset, int from, int to, int k)

public static float score(byte[] bases, float[] vec, CellNet net, boolean rcomp)

public static int calcKSpace(int k)

*Produces a condensed kmer space
public static int[] kmap(int k, int maxDims)

public static void setDimensions(int maxDims)

private static void fillArrays(int maxDims)

@Override protected EntropyTracker[] initialValue()

</class SequenceToVector>
<class Sigmoid>
public class Sigmoid

#Fields
static final String name="SIG"

static final Sigmoid instance=new Sigmoid()


#Methods
private Sigmoid()

</class Sigmoid>
<class Source>
public abstract class Source

#Fields
protected float value=0f


#Methods
public Source()

public float value()

public int id()

public float bias()

void setValue(float v)

public boolean check()

*True only if this has no inputs
public boolean terminal()

</class Source>
<class Status>
class Status

#Fields
final CellNet net

String s

final int epoch

final float alpha

final float anneal

int count=1


#Methods
Status(CellNet net_, int epoch_, float alpha_, float anneal_)

@Override public int compareTo(Status b)

@Override public int hashCode()

@Override public String toString()

@Override public boolean equals(Object b)

public boolean equals(Status b)

</class Status>
<class Subset>
public class Subset

#Fields
final Sample[] samples

final Sample[] positive

final Sample[] negative

private final Random randy=new Random(0)

int nextFullPassEpoch=-1

int numShuffles=0


#Methods
public Subset(ArrayList<Sample> sampleList)

void sortSamples(float fraction, boolean allowMultithreadedSort)

void sortSamples2(float sortFraction, int useSamples, boolean allowMultithreadedSort, FloatList pivots)

private static final void sort(Sample[] samples, FloatList pivots, int lim, boolean mt)

private static final void pivotSort(Sample[] samples, FloatList pivots, int sortLim, int swapLim, boolean mt)

void triage(long currentEpoch, long startTriage, float positiveTriage, float negativeTriage)

void shuffle()

public void reset()

</class Subset>
<class Swish>
public class Swish

#Fields
static final String name="SWISH"

static final Swish instance=new Swish()


#Methods
private Swish()

</class Swish>
<class Tanh>
public class Tanh

#Fields
static final String name="TANH"

static final Tanh instance=new Tanh()


#Methods
private Tanh()

</class Tanh>
<class Trainer>
*Trains a neural network.
*@author Brian Bushnell
*@date February 6, 2023
public class Trainer

#Fields
private final String commandLine

final ArrayList<String> commands

*Primary input file path
private String netIn=null

*Secondary input file path
private String dataIn=null

*Secondary input file path
private String validateIn=null

*Output data path
private String dataOut=null

*Primary output file path
private String netOutFinal=null

*Output file path for best intermediate network
private String netOutBest=null

private int[] dims0

private int[] minDims

private int[] maxDims

private int numInputs=-1

private int numOutputs=-1

private int numLayers=-1

SampleSet data

SampleSet validateSet

float validateFraction=0.1f

boolean exclusive=true

private int netsMade=0

private float maxDensity=1.0f

private float maxDensity1=0f

private int edgeBlockSize=1

private long maxEdges=-1

private float[] densityArray=null

private long netSeed0=-1

private boolean setNetSeed=false

int threads=1

boolean orderedJobs=true

ArrayBlockingQueue<CellNet> networkQueue

ArrayBlockingQueue<JobData> workerQueue

ArrayBlockingQueue<ArrayList<Seed>> seedQueue

private final Profiler mprof=new Profiler("M",13)

private final Profiler wprof=new Profiler("W",7)

ArrayList<WorkerThread> alwt

boolean training=true

int maxEpochs=400000

float targetError=-1

float targetFPR=-1

float targetFNR=-1

float crossoverFpMult=1

boolean sortAll=false

boolean sort=true

boolean sortInThread=false

boolean shuffleSubset=true

boolean launchInThread=false

boolean allowMTSort=true

static boolean PIVOT_SORT=false

static int SHUFFLEMOD=4

boolean useSetLock=true

static boolean setNetInWorkerThread=true

static boolean copyNetInWorkerThread=false

double alphaZero=0.08f

double alphaMult=5.0f

double alphaMult2=2.8f

int peakAlphaEpoch=640

float annealStrength0=.003f

float annealProb=.225f

float annealMult2=800

double annealDropoff0=0.999975f

float maxAnnealEpochMult=0.8f

int minAnnealEpoch=400

int maxAnnealEpoch=Integer.MAX_VALUE

static float cutoffForEvaluation=0.5f

static boolean setCutoffForEvaluation=false

int subsets=-1

int setsize=60000

float fractionPerEpoch0=0.08f

float fractionPerEpoch2=0.08f

int fpeStart=192

float dumpRate=0.5f

private float dumpEpochMult=0.25f

int dumpEpoch=-1

float partialDumpFraction=0.9f

final boolean shrinkSubsets=true

float positiveTriage=0.0001f

float negativeTriage=0.0005f

int startTriage=-1

float startTriageMult=0.2f

int minWeightEpoch=-1

float minWeightEpochMult=0.03f

boolean forcePrintFPR=false

boolean forcePrintFNR=false

final boolean printFPR

final boolean printFNR

boolean printTPR=false

boolean printTNR=false

boolean printCutoff=true

boolean printAlpha=false

boolean printAnneal=false

double annealStrength

double annealDropoff

final double alphaIncrease

final int alphaEpochs

final double alphaDropoff

int jobsPerEpoch

int networksPerCycle=1

int cycles=1

long networksTested=0

private LongList seedList

private int seedsToScan=-1

private float seedsToScanMult=0

private int scanEpochs=1024

private int scanSamples=80000

int lastPrintEpoch=-1

private CellNet finalNet=null

private CellNet bestNet=null

int printInterval=10000

boolean quiet=false

boolean printStatus=true

boolean machineOut=false

int printMode=printAverage

long lastPrintTime=-1

private static final int printFirst=0

private static final int printAll=1

private static final int printBest=2

private static final int printAverage=3

HashMap<CellNet,CellNet> networkMap=new HashMap<CellNet,CellNet>()

HashMap<CellNet,ArrayList<CellNet>> networkMap2=new HashMap<CellNet,ArrayList<CellNet>>()

ArrayList<CellNet> finalNets=new ArrayList<CellNet>()

private long linesProcessed=0

private long linesOut=0

private long bytesProcessed=0

private long bytesOut=0

private long edgesIn=0

private long networksIn=0

private int maxLines=Shared.MAX_ARRAY_LEN

int maxLinesV=-1

private boolean shuffleRaw=false

private float balance=0.4f

*Network Input File
private final FileFormat ffNetIn

*Data Input File
private final FileFormat ffDataIn

*Data Input File
private final FileFormat ffValidateIn

*Data Output File
private final FileFormat ffDataOut

*Network Output File
private final FileFormat ffNetOutFinal

*Intermediate Output File
private final FileFormat ffNetOutBest

final Random randyNetSeed

private final ReadWriteLock rwlock=new ReentrantReadWriteLock()

*Print status messages to this output stream
private PrintStream outstream=System.err

*Print verbose messages
public static boolean verbose=false

*True if an error was encountered
public boolean errorState=false

*Overwrite existing output files
private boolean overwrite=true

*Append to existing output files
private boolean append=false


#Methods
*Code entrance from the command line.
*@param args Command line arguments
public static void main(String[] args)

*Constructor.
*@param args Command line arguments
public Trainer(String[] args)

*Parse arguments from the command line
private Parser parse(String[] args)

*Add or remove .gz or .bz2 as needed
private void fixExtensions()

*Ensure files can be read and written
private void checkFileExistence()

*Adjust file-related static fields as needed for this program
private static void checkStatics()

*Ensure parameter ranges are within bounds and required parameters are set
private boolean validateParams()

*Create read streams and process all data
void process(Timer t)

private String toMachineHeader(int[] dims)

private String toMachineOut(Timer t)

*Spawn process threads
private void spawnThreads()

private int calcSeedsToScan()

private CellNet trainNetworks()

private CellNet runCycle()

X fetchFromQueue(ArrayBlockingQueue<X> queue)

CellNet compareWithBest(CellNet net)

CellNet compare(CellNet a, CellNet b)

Status compare(Status a, Status b)

private final void accumulate(TrainerThread tt)

private final void accumulate(ScannerThread tt)

@Override public final void accumulate(WorkerThread wt)

@Override public final boolean success()

private ArrayList<Seed> scanForSeeds(int seedsToScan0, int seedsToReturn0)

private CellNet[] fetchNetworks(String path, int count)

private CellNet[] createNetworks(int count)

private CellNet randomNetwork()

public final CellNet randomNetwork(long seed)

public static final CellNet randomNetwork(int[] dims, long seed, float maxDensity, float maxDensity1, long maxEdges, int edgeBlockSize, ArrayList<String> commands)

public static long fullyConnectedEdges(int[] dims)

public static final int[] makeDims(int[] minDims, int[] maxDims, long seed)

private CellNet[] loadNetworks(String path)

private CellNet loadNetwork(String path)

private void writeNetwork(CellNet net, FileFormat ff)

private SampleSet[] loadData(String path, boolean makeSubsets, int maxLines0, boolean shuffleRaw, float splitFraction, int maxLines1)

private void writeData(FileFormat ff)

void clearCycle()

private static String plural(String s, int count)

private static String pluralES(String s, int count)

void printStatus(CellNet net)

private ArrayList<CellNet> concentrateBest(ArrayList<CellNet> list)

private CellNet makeAvg(ArrayList<CellNet> list0)

private float[] genAvgDims(ArrayList<CellNet> list0)

private String genAvgDimsString(ArrayList<CellNet> list0, boolean machine)

private String genDimsString(int[] dims, boolean machine)

private void printStatusInner(CellNet net)

void printStatusOld(CellNet net, String status, int epoch)

String genPrintStringFull(CellNet net, long millis)

String genPrintStringDefault(CellNet stat, long millis)

private String genPrintString(CellNet net, long millis, boolean epo, boolean fpr, boolean fnr, boolean tpr, boolean tnr, boolean ctf, boolean alp, boolean ann)

private String genPrintStringMachine(CellNet net)

private static ByteStreamWriter makeBSW(FileFormat ff)

@Override public final ReadWriteLock rwlock()

</class Trainer>
<class TrainerThread>
public class TrainerThread

#Fields
private final Trainer parent

private final CellNet net0

private final CellNet net00

private final CellNet[] subnets

private SampleSet data

private SampleSet validateSet

private final FloatList flist

private Subset currentSubset

private Sample[] currentSamples

private final ReentrantReadWriteLock setLock

private final int jobsPerEpoch

private final boolean orderedJobs

private final ArrayBlockingQueue<JobResults> jobResultsQueue

private final ArrayBlockingQueue<JobData> workerQueue

private final ArrayBlockingQueue<JobData> launchQueue

final Profiler mprof=new Profiler("M",13)

private final boolean training

final int maxEpochs

final float targetError

final float targetFPR

final float targetFNR

final float crossoverFpMult

final boolean sortAll

final boolean sort

final boolean sortInThread

final boolean shuffleSubset

final boolean launchInThread

final boolean allowMTSort

final double alphaZero

final double alphaMult

final double alphaMult2

final int peakAlphaEpoch

final double alphaIncrease

final int alphaEpochs

final double alphaDropoff

final float annealStrength0

final float annealProb

final float annealMult2

final double annealDropoff0

final int minAnnealEpoch

final int maxAnnealEpoch

private final float fractionPerEpoch0

private final float fractionPerEpoch2

private float fpeMult=1.0f

private final int fpeStart

private final float positiveTriage

private final float negativeTriage

private final int startTriage

private final boolean printStatus

private final int printInterval

private final float dumpRate

private final int dumpEpoch

private final int minWeightEpoch

private final float minWeightEpochInverse

float bestErrorRate=999

float bestFNR=999

double rawErrorSum=0

double weightedErrorSum=0

long tpSum=0

long tnSum=0

long fpSum=0

long fnSum=0

double rawErrorRate=999f

double weightedErrorRate=999f

double fpRate=0

double fnRate=0

double tpRate

double tnRate

double lastCutoff=999f

double annealStrength

double annealDropoff

double alpha

private int nextPrintEpoch=1

private int samplesThisEpoch=-1

private boolean validateThisEpoch=false

private int currentEpoch=0

final Random randyAnneal

*Print status messages to this output stream
private PrintStream outstream=System.err

*Print verbose messages
public static boolean verbose=false

*True if an error was encountered
public boolean errorState=false


#Methods
public TrainerThread(Trainer parent_, CellNet net0_)

@Override public void run()

private int runEpochs()

@Deprecated private void dump_old(SampleSet data)

private void dump(SampleSet data)

private void dumpList(ArrayList<Sample> inList, ArrayList<Sample> outList, int retainCount)

private void runTrainingInterval()

private final float weightMult()

private void runTestingInterval(Sample[] set)

void lock()

void unlock()

private void anneal()

private void adjustAlpha()

private void triage()

private int launchJobs(CellNet net0, Sample[] set, int numSamples, boolean backprop, float weightMult, boolean sort)

private int launchJobsInner(CellNet net0, Sample[] set, int numSamples_, int epoch, double alpha, boolean backprop, float weightMult, boolean sort)

private int launchJobs_SetLock(CellNet net0, Sample[] set, int numSamples_, int epoch, double alpha, boolean backprop, float weightMult, boolean sort)

private void gatherResults(CellNet net0, ArrayBlockingQueue<JobResults> mq, boolean accumulate, int numJobs)

private void gatherResultsDisordered(CellNet net0, ArrayBlockingQueue<JobResults> mq, boolean accumulate, int numJobs)

private void gatherResultsOrdered(CellNet net0, ArrayBlockingQueue<JobResults> mq, boolean accumulate, int numJobs)

private boolean handlePrintInterval()

float calcFractionPerEpoch()

int calcSamplesThisEpoch(Subset currentSubset)

private void selectTrainingSubset()

private void clearStats()

private void gatherStats(JobResults job)

private void mergeStats(int samples)

void calcNetStats(boolean retainOldCutoff)

private void setNetStats(CellNet net)

public final boolean success()

</class TrainerThread>
<class WorkerThread>
class WorkerThread

#Fields
private JobData job

private final ArrayBlockingQueue<JobData> jobQueue

private final float cutoffForEvaluation

private double errorSum=0

private double weightedErrorSum=0

private int tpSum=0

private int tnSum=0

private int fpSum=0

private int fnSum=0

private ArrayList<Sample> samples

private final ArrayList<Sample> positive=new ArrayList<Sample>()

private final ArrayList<Sample> negative=new ArrayList<Sample>()

private int maxSamples=0

final Profiler tprof=new Profiler("W",7)

*Number of reads processed by this thread
protected long linesProcessedT=0

*Number of reads retained by this thread
protected long linesOutT=0

protected boolean errorStateT=false

*True only if this thread has completed successfully
boolean success=false

private int epoch=0

private boolean backprop

*Thread ID
final int tid

private CellNet net


#Methods
WorkerThread(int tid_, ArrayBlockingQueue<JobData> wq, float cutoffForEvaluation_)

@Override public void run()

*Iterate through the lines
void processInner()

JobData getJob()

void prepareForWork(JobData job)

int processSamples(float weightMult)

void sendResults(int samplesProcessed, JobData job)

*Process a sample.
*@param line sample number
void processSample(Sample sample, boolean backprop, float weightMult)

void sortSamples(JobData job)

void addToStats(Sample s)

private void clearStats()

@Override public int compareTo(WorkerThread o)

</class WorkerThread>
